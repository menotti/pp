{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNcg/TmF6cqk/1BIBFf0xhj"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-EZFTgQcHIAc"},"source":["# PPD: OpenMP\n","\n","Hélio - DC/UFSCar - 2023"]},{"cell_type":"markdown","metadata":{"id":"BP2UF_h7R0-I"},"source":["# Programação paralela com extensões de linguagem: OpenMP\n","\n","Há algum tempo, o aumento de desempenho dos sistemas computacionais passou a ser buscado a partir da replicação de suas unidades funcionais, já que estava cada vez mais difícil simplesmente aumentar a velocidade dos processadores. \n","\n","Processadores com vários núcleos (*cores*) e múltiplos processadores passaram a ser utilizados em computadores servidores e até em computadores pessoais e smartphones!\n","\n","Como resultado, programadores que buscam aumentar o desempenho de suas aplicações passaram a ter que paralelizar os códigos utilizados. Visto pela complexidade da [programação com a biblioteca de *pthreads*](https://computing.llnl.gov/tutorials/pthreads/), contudo, essa não é uma tarefa fácil. \n","\n","Por outro lado, também não é simples para um compilador detectar automaticamente quais atividades de um programa podem ser executadas em paralelo e ajustar o código para isso. Questões relacionadas a dependências de dados tanto podem fazer com que um programa tenha trechos paralelizados de maneira indevida, quanto que sejam mantidos sequenciais em situações em que o compilador não tem certeza da ausência de erros com a  paralelização.\n","\n","Assim, uma estratégia intermediária foi considerada para a **transformação de código sequencial** existente **em código paralelo**: **usar dicas do programador**, na forma de marcas (**pragmas**) adicionadas ao código, e paralelização dos cógigos indicados, usando *threads*, feita pelo compilador.\n","\n","**OpenMP** (*Open Multi-Processing* - http://openmp.org) é uma interface de programação (API) que possibilita o desenvolvimento de programas em C/C++ e Fortran para ambientes multiprocessados.\n","\n","Definido por um grupo formado por grandes fabricantes de hardware e software, OpenMP é um modelo portável e escalável que provê uma interface simples e flexível para o desenvolvimento de aplicações paralelas para execução em computadores com memória compartilhada.\n","\n","Diferentes arquiteturas são suportadas, variando de estações de trabalho a supercomputadores, incluindo plataformas Unix e Windows.\n","\n","De maneira geral, OpenMP consiste em um conjunto de diretivas de compilação, em uma biblioteca de funções e em variáveis de ambiente que influenciam o comportamento da execução de programas.\n","\n","# Modelo de programação\n","\n","Originalmente, o modelo de programação oferecido por OpenMP é o de paralelismo baseado em *threads* para ambiente com memória compartilhada (*Shared Memory, Thread Based Paralelism*). Assim, o cenário típico para uso desse mecanismo são os computadores ***multicores***. \n","\n","    Versões mais recentes das especificações OPenMP também têm suporte para paralelismo \n","    usando aceleradores e GPGPUs mas, por ora, trataremos de CPUs.\n","\n","OpenMP permite:\n","\n","* Criar times de *threads* para execução paralela de blocos de código\n","* Especificar como dividir (*share*) as atividades de um bloco de código entre os membros de um grupo\n","* Declarar variáveis compartilhadas e privadas\n","* Sincronizar *threads* e permitir que executem operações de maneira exclusiva\n","* Executar *loops* usando operações SIMD\n","* Utilizar dispositivos como GPUs para processamento vetorial\n","\n","OpenMP suporta ambos os modelos de [decomposição](https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial#Designing) das atividades: decomposição de código (funcional) e decomposição dados (de domínio).\n","\n","* Paralelismo das atividade com OpenMP é definido de maneira explícita, não automática, com controle total do programador.\n","* Paralelismo é especificado por diretivas de compilação (pragmas em C/C++ (*pragmatic information*)), que permitem passar informações ao compilador.\n","* Informações passadas pelos *pragmas* podem ser ignoradas pelo compilador sem alterar a correção do código gerado.\n","* Esforço de paralelização de um programa com OpenMP resume-se, em geral, à identificação do paralelismo e não à reprogramação do código para implementar o paralelismo desejado.\n","\n","Diferentes compiladores têm suporte à programacão com OpenMP: [compilers and tools](https://www.openmp.org/resources/openmp-compilers-tools/).\n","\n","# Compilando programas OpenMP com gcc\n","\n","Como OpenMP trata de extensões de linguagem, o suporte ao seu uso também deve ser oferecido diretamente **pelo compilador** utilizado. Assim, não basta apenas incluir definições e ligar bibliotecas ao código, mas é preciso saber quais parâmetros são necessários pelo compilador em uso.\n","\n","Diferentes implementações de compiladores C/C++ e Fortran têm suporte a OpenMP, o que inclui [gcc](https://gcc.gnu.org/wiki/openmp).\n","\n","Para compilar e gerar código executável C com OpenMP em gcc:\n","```\n","$ gcc prog.c -o prog -fopenmp  ...         // compila programa, incluindo suporte para openmp\n","````\n","Para saber mais, vale ler o manual:\n","```\n","$ man gcc                // sempre bom consultar o manual :-)\n","\n","  /openmp                // busca por openmp ...\n","\n","-fopenmp \n","  Enable handling of OpenMP directives \"#pragma omp\" in C/C++ ... \n","  When -fopenmp is specified, the compiler generates parallel code according\n","  to the  OpenMP Application Program Interface v2.5 <http://www.openmp.org/>.\n","  This option implies -pthread, and thus is only supported on targets that \n","  have support for -pthread.\n","```\n"]},{"cell_type":"markdown","source":["Vale saber também que as especificações OpenMP foram evoluindo ao longo do tempo e incluindo novas funcionaliddes. Assim, pode ser relevante saber qual é a versão OpenMP suportada pelo compilador. \n","\n","\n","https://www.openmp.org/specifications/\n"," \n","    OpenMP 5.2 Specification – Nov 2021\n","    OpenMP 5.1 Specification – Nov 2020\n","    OpenMP 5.0 Specification – Nov 2018\n","    OpenMP 4.5 Specification – Nov 2015\n","    OpenMP 4.0 Specification – Jul 2013\n","    OpenMP 3.1 Specification – Jul 2011\n","\n","\n","Usando o compilador *gcc*, por exemplo, pode-se saber a verão OpenMP suportada consultando-se um valor pré-definido pela biblioteca *incluída* no programa:\n","\n","    The _OPENMP macro is defined by OpenMP-compliante implementations as the decimal constant\n","    yyyymm, which will be the year and month of the approved specification."],"metadata":{"id":"HJswX65bZnOa"}},{"cell_type":"code","source":["%%writefile version.c\n","\n","#include <omp.h> \n","#include <stdio.h> \n","\n","int \n","main()\n","{\n","  /*\n","    https://www.openmp.org/specifications/\n","\n","    The _OPENMP macro is defined by OpenMP-compliante implementations as the decimal constant\n","    yyyymm, which will be the year and month of the approved specification.\n"," \n","    OpenMP 5.2 Specification – Nov 2021\n","    OpenMP 5.1 Specification – Nov 2020\n","    OpenMP 5.0 Specification – Nov 2018\n","    OpenMP 4.5 Specification – Nov 2015\n","    OpenMP 4.0 Specification – Jul 2013\n","    OpenMP 3.1 Specification – Jul 2011\n","  */\n"," \n","#ifdef _OPENMP\n","  printf(\"Compiled by an OpenMP-compliant implementation: %d\\n\",_OPENMP);\n","#endif\n","\n","  return 0;\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2Zq_ZUfZrr2","executionInfo":{"status":"ok","timestamp":1673289131929,"user_tz":180,"elapsed":8,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}},"outputId":"36711453-1a72-49d7-94de-f3e98f1561f4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing version.c\n"]}]},{"cell_type":"code","source":["! if [ ! version -nt version.c ]; then gcc version.c -o version -fopenmp && ./version; fi\n","# ! clang version.c -o clang-ver -fopenmp -stdlib=libc++ -Xopenmp && ./clang-ver"],"metadata":{"id":"utiyYh5ZZ6lS","executionInfo":{"status":"ok","timestamp":1673289379018,"user_tz":180,"elapsed":401,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lIawix79ekOe"},"source":["# Paralelismo com OpenMP\n","\n","De maneira geral, a paralelização de códigos com OpenMP é feita da seuinte forma: \n","\n","* programador insere diretivas (**#pragmas**) no código, indicando ao compilador qual linha ou bloco de código devem ser paralelizados e de qual forma;\n","* compilador identifica as diretivas e transforma o código sequencial em um código paralelo.\n","\n","Diretivas (pragmas) são inseridas como linhas de código e aplicam-se à linha de código logo abaixo. Quando o objetivo é aplicar uma diretiva a um bloco de código, com várias linhas, é preciso envolver este bloco de código com o uso de chaves \"{ ... }\". \n","\n","As diretivas OpenMP especificadas como *pragmas* têm a seguinte sintaxe:\n","\n","```\n","#pragma omp nome_da_diretiva [ cláusulas_da_diretiva ]\n","```\n","\n","Como se observa, primitivas podem, opciohnalmente, ter **cláusulas** variadas, que definem aspectos do funcionamento da diretiva. \n","\n","Caso o compilador utilizado não tenha suporte a OpenMP, ou se o parâmetro ***-fopenmp*** não for especificado na invocação do compilador ***gcc***, por exemplo, as linhas contendo as diretivas (#pragmas) serão simplesmente ignoradas pelo compilador. \n","\n","<br>\n","\n","Os exemplos a seguir mostram a paralelização de um bloco de código usando a diretiva ***parallel***, especificada como uma *pragma* no código. \n","\n","\n","No exemplo abaixo, vemos o uso da diretiva *parallel* para criar um time de *threads*. As diretivas sempre se aplicam à linha de código imediatamente abaixo, ou ao bloco de código definido entre chaves \\{ ... \\} . Neste caso, tudo que está dentro do bloco de código definido a partir da linha seguinte à *pragma*, será executado por todas as *threads* do time. \n","\n","Nesse caso, vê-se também que a **diretiva *parallel*** tem uma cláusula, **num_threads(4)**, que especifica quantas *threads* deverão ser usadas para a execução paralela do bloco a seguir. \n","\n","Apenas uma *thread*, aquela que encontrou a construção paralela e criou o time de *threads*, prossegue em execução após a região paralela. Neste caso, era a *thread* associada à função *main*. Apenas essa *thread* prossegue em execução, de forma que o comando printf final neste caso só será executado uma vez.\n","\n"]},{"cell_type":"code","metadata":{"id":"bjGR6mIMgtuE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672845898767,"user_tz":180,"elapsed":413,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}},"outputId":"9ed2f0e2-2d10-4346-a663-23e2b71aa6ef"},"source":["%%writefile p1.c\n","\n","#include <stdio.h>\n","\n","int main ()\n","{\n","  // ...   // Código serial, executado por apenas 1 thread, como usual\n","  // ...\n","\n","  // Uso da diretiva parallel para criar uma região paralela:\n","  #pragma omp parallel num_threads(4)  \n","  {\n","    // Seção paralela, executada por todas as threads do time\n","    printf(\"Hello, world!\\n\"); \n","  }\n","  // Ao fim do bloco de código da região paralela, a thread master espera pela conclusão das demais\n","  // Apenas thread master (aquela que encontrou a região paralela e criou o time) prossegue execução\n","  \n","  printf(\"Goodbye\\n\");\n","  // ...\n","  return 0;\n","}\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting p1.c\n"]}]},{"cell_type":"code","metadata":{"id":"6mvC_pCofB1v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672845850792,"user_tz":180,"elapsed":826,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}},"outputId":"eddbbc48-c814-4862-9fd8-5746d40ce4d2"},"source":["! gcc p1.c -o p1 -fopenmp && ./p1\n","! echo\n","# Observe que se o código for compilado sem o parâmetro \"-fopenmp\" as linhas com pragmas serão ignoradas e não haverá paralelismo\n","! gcc p1.c -o p1 && ./p1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Hello, world!\n","Hello, world!\n","Hello, world!\n","Hello, world!\n","Goodbye\n","\n","Hello, world!\n","Goodbye\n"]}]},{"cell_type":"markdown","metadata":{"id":"6sUaifQOfc6G"},"source":["Neste segundo exemplo, repete-se a criação de um time de *threads* para execução paralela de um bloco de código. É importante observar que, como não foram especificadas quantas *threads* usar, o compilador tomará como base um valor *default*, que é igual ao número de núcleos de processamento (cores) existentes no sistema. O controle sobre o número de *threads* será tratado com mais detalhes posteriormente.\n","\n","Outro aspecto a observar é o uso de 2 chamadas da API omp. Para usá-las, é preciso incluir o arquivo de cabeçalhos ***omp.h*** no código. \n","\n","A função ***omp_get_thread_num***() retorna o número lógico de cada *thread* dentro do time que está executando a região paralela. \n","\n","Já a função ***omp_get_num_threads***() indica quantas *threads* há no time atual. O conhecimento desses índices pode ser útil quando o programador deseja controlar explicitamente o que cada *thread* do time irá fazer."]},{"cell_type":"code","metadata":{"id":"CsT7LCJgegX6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672845968995,"user_tz":180,"elapsed":415,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}},"outputId":"d1aeda95-1b0f-430a-8986-8b6fc30f7157"},"source":["%%writefile p2.c\n","\n","#include <stdio.h>\n","#include <omp.h>   // necessário apenas se formos usar funções da API omp\n","\n","// ...\n","\n","int main ()\n","{\n","  // ...\n","  // Início de seção paralela: geração das threads do time\n","  #pragma omp parallel \n","  {\n","    // ...\n","    // Seção paralela, executada por todas as threads do time\n","    printf(\"Esta é a thread %d de um time de %d.\\n\", omp_get_thread_num(), omp_get_num_threads());\n","    // ...\n","  }  \n","  // Apenas master thread prossegue execução após o bloco paralelo\n","  // ...\n","  return 0;\n","}\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing p2.c\n"]}]},{"cell_type":"code","metadata":{"id":"OuGs_69FfjNX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672845979053,"user_tz":180,"elapsed":464,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}},"outputId":"6f6fe510-c010-4264-dcdb-9ce146d97a20"},"source":["! gcc -Wall p2.c -o p2 -fopenmp && ./p2"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Esta é a thread 0 de um time de 2.\n","Esta é a thread 1 de um time de 2.\n"]}]},{"cell_type":"markdown","metadata":{"id":"lqxss_bigJ02"},"source":["Um aspecto importante na programação com *threads* é tratamento das variávies do programa. Como *threads* compartilham as áreas de memória do processo ao qual estão associadas, é preciso atenção para qual será o efeito da criação automática de várias *threads* no programa com relaçào às variáveis utilizadas.\n","\n","No exemplo a seguir, ilustra-se a definição de escopo de variáveis dentro de um bloco paralelo. Por padrão, qualquer **variável global**, ou qualquer variável definida dentro da função *main* neste caso, que é acessível dentro do código da região paralela, será **compartilhada** por todas as *threads* do time. Isso significa que qualquer modificação de uma dessas variáveis ocorrerá sobre a única instância, compartilhada por todas as *threads* do processo.\n","\n","Na criação de um time de *threads* com a diretiva ***parallel***, contudo, há cláusulas específicas que podem ser usadas para **definir o escopo** de variáveis: \n","\n","* a cláusula ***private***() indica uma lista de variáveis que serão **privadas**, ou seja, cada *thread* terá uma cópia dessas variáveis;\n","* já a cláusula ***shared***() indica que as variáveis listadas serão **compartilhadas** pelas *threads* do time. \n","\n","Por padrão, variáveis não mencionadas nas cláusulas são tratadas como **compartilhadas**. Assim, todas as referências a uma variável vão se referir à mesma posição de memória. Caso esse não seja o comportamento desejado, é preciso especificar esta variável na lista de variáveis privadas.\n","\n","Variáveis que forem definidas dentro do bloco paralelo (o que é permitido se não for usada a sintaxe C ansi ou -std=c90) também serão privadas para cada thread. \n"]},{"cell_type":"code","metadata":{"id":"FN5cdHnoesvv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672846783977,"user_tz":180,"elapsed":411,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}},"outputId":"73064604-3e7a-4bc4-8e94-af7fe29e2f5e"},"source":["%%writefile p3.c\n","\n","#include <stdio.h>\n","#include <stdlib.h>  // para funcao rand()\n","#include <time.h>    // para funcao time()\n","#include <omp.h>     // necessário apenas se formos usar funções da API omp\n","\n","int main ()\n","{\n","  int var1, var2;\n","  // ...\n","  srand(time(NULL));\n","  \n","  var2 = 0;\n","  \n","  // Região paralela com definição do escopo de variáveis usadas no trecho paralelo.\n","  #pragma omp parallel private(var1) shared(var2)\n","  {\n","    int ind;      // variáveis definidas dentro da região paralela são privadas para cada thread do time\n","    \n","    ind = omp_get_thread_num();   // obtem numero logico da thread e salva em índice local\n","\n","    // ...\n","    var1 = rand(); // como var1 é privada, cada thread terá uma instância de variável com esse nome\n","    // ...\n","   \n","    // var2 =      // será que todas as threads podem atualizar essa variavel ao mesmo tempo?\n","    \n","    printf(\"Thread %d: var1 = %d\\n\", ind, var1);\n","\n","    // ...\n","  }\n"," \n","  // Apenas master thread prossegue execução após o bloco paralelo\n","  printf(\"\\nFim\\n\");\n","  \n","  // ...\n","  return 0;\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting p3.c\n"]}]},{"cell_type":"code","metadata":{"id":"azxi39IEgN9r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672846793300,"user_tz":180,"elapsed":369,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}},"outputId":"459ea85c-a7b5-431f-e26c-f57d792c61e6"},"source":["! gcc p3.c -o p3 -fopenmp && ./p3"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thread 0: var1 = 613363060\n","Thread 1: var1 = 627224178\n","\n","Fim\n"]}]},{"cell_type":"markdown","metadata":{"id":"O_M_bBjeZ5va"},"source":["##Quantas *threads* são usadas numa região paralela?\n","\n","Número de *threads* numa região paralela é determinado por diversos fatores:\n","\n","* Avaliação da cláusula IF \n","* Ajuste da cláusula ***num_threads*** na diretiva\n","* Uso da função ***omp_set_num_threads()*** antes da diretiva parallel\n","* Ajuste da variável de ambiente **OMP_NUM_THREADS** antes de iniciar a execução do programa\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JeDKT0M-Z-gn","executionInfo":{"status":"ok","timestamp":1672846854427,"user_tz":180,"elapsed":332,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}},"outputId":"0173e17a-8129-4b10-8298-018939fe821f"},"source":["%%writefile p4.c\n","\n","#include <stdio.h>\n","#include <stdlib.h>   // para rand()\n","#include <time.h>     // para time()\n","#include <omp.h>      // para funções OpenMP\n","\n","int\n","main()\n","{\n","  int impar;\n"," \n","  #pragma omp parallel\n","  printf(\"Thread %d de %d\\n\",omp_get_thread_num(), omp_get_num_threads());\n"," \n","  printf(\"\\n\");\n"," \n","  #pragma omp parallel num_threads(4)\n","  printf(\"Thread %d de %d\\n\",omp_get_thread_num(), omp_get_num_threads());\n","\n","  printf(\"\\n\");\n"," \n","  omp_set_num_threads(6);\n"," \n","  #pragma omp parallel\n","  printf(\"Thread %d de %d\\n\",omp_get_thread_num(), omp_get_num_threads());\n","\n","  printf(\"\\n\");\n"," \n","  srand(time(NULL));\n","  impar = rand()%2;\n"," \n","  #pragma omp parallel if(impar)\n","  printf(\"Thread %d de %d\\n\",omp_get_thread_num(), omp_get_num_threads());\n","     \n","  return 0;\n","}"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting p4.c\n"]}]},{"cell_type":"code","metadata":{"id":"2l7grDJ_jXLw"},"source":["! gcc -Wall p4.c -o p4 -fopenmp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oIU_UIjAbsS3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672846882827,"user_tz":180,"elapsed":531,"user":{"displayName":"Helio Crestana Guardia","userId":"13491677459342948690"}},"outputId":"0ced220b-a2aa-4bef-b09e-3cbe3e50baa7"},"source":["! lscpu | grep \"CPU(s)\" && \\\n"," echo && echo \"Executando sem ajustar OMP_NUM_THREADS\" && echo \"\" && \\\n"," ./p4 && \\\n"," echo \"\" && echo \"Executando com OMP_NUM_THREADS=3\" && echo \"\" && \\\n"," OMP_NUM_THREADS=3 ./p4"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CPU(s):              2\n","On-line CPU(s) list: 0,1\n","NUMA node0 CPU(s):   0,1\n","\n","Executando sem ajustar OMP_NUM_THREADS\n","\n","Thread 0 de 2\n","Thread 1 de 2\n","\n","Thread 1 de 4\n","Thread 3 de 4\n","Thread 2 de 4\n","Thread 0 de 4\n","\n","Thread 5 de 6\n","Thread 2 de 6\n","Thread 0 de 6\n","Thread 3 de 6\n","Thread 1 de 6\n","Thread 4 de 6\n","\n","Thread 1 de 6\n","Thread 3 de 6\n","Thread 0 de 6\n","Thread 2 de 6\n","Thread 5 de 6\n","Thread 4 de 6\n","\n","Executando com OMP_NUM_THREADS=3\n","\n","Thread 2 de 3\n","Thread 0 de 3\n","Thread 1 de 3\n","\n","Thread 1 de 4\n","Thread 2 de 4\n","Thread 3 de 4\n","Thread 0 de 4\n","\n","Thread 5 de 6\n","Thread 3 de 6\n","Thread 1 de 6\n","Thread 0 de 6\n","Thread 2 de 6\n","Thread 4 de 6\n","\n","Thread 0 de 1\n"]}]}]}